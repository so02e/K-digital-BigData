{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 메인교재 PART 7 - 머신러닝 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단순회귀분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 7-1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "'''\n",
    "[Step 1] 데이터 준비 - read_csv() 함수로 자동차 연비 데이터셋 가져오기\n",
    "'''\n",
    "# CSV 파일을 데이터프레임으로 변환\n",
    "df = pd.read_csv('./data/auto-mpg.csv', header=None)\n",
    "\n",
    "# 열 이름 지정\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight',\n",
    "              'acceleration','model year','origin','name'] \n",
    "\n",
    "# 데이터 살펴보기\n",
    "print(df.head())   \n",
    "print('\\n')\n",
    "\n",
    "#  IPython 디스플레이 설정 - 출력할 열의 개수 한도 늘리기\n",
    "pd.set_option('display.max_columns', 10)\n",
    "print(df.head())   \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Step 2] 데이터 탐색\n",
    "'''\n",
    "\n",
    "# 데이터 자료형 확인\n",
    "print(df.info())  \n",
    "print('\\n')\n",
    "\n",
    "# 데이터 통계 요약정보 확인\n",
    "print(df.describe())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# horsepower 열의 자료형 변경 (문자열 ->숫자)\n",
    "print(df['horsepower'].unique())          # horsepower 열의 고유값 확인\n",
    "print('\\n')\n",
    "\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)      # '?'을 np.nan으로 변경\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True)   # 누락데이터 행을 삭제\n",
    "df['horsepower'] = df['horsepower'].astype('float')      # 문자열을 실수형으로 변환\n",
    "\n",
    "print(df.describe())                                     # 데이터 통계 요약정보 확인\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Step 3] 속성(feature 또는 variable) 선택\n",
    "'''\n",
    "\n",
    "# 분석에 활용할 열(속성)을 선택 (연비, 실린더, 출력, 중량)\n",
    "ndf = df[['mpg', 'cylinders', 'horsepower', 'weight']]\n",
    "print(ndf.head())   \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 종속 변수 Y인 \"연비(mpg)\"와 다른 변수 간의 선형관계를 그래프(산점도)로 확인\n",
    "# Matplotlib으로 산점도 그리기\n",
    "ndf.plot(kind='scatter', x='weight', y='mpg',  c='coral', s=10, figsize=(10, 5))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn으로 산점도 그리기\n",
    "fig = plt.figure(figsize=(10, 5))   \n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "sns.regplot(x='weight', y='mpg', data=ndf, ax=ax1, color=\"red\")                 # 회귀선 표시\n",
    "sns.regplot(x='weight', y='mpg', data=ndf, ax=ax2, fit_reg=False)  #회귀선 미표시\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn 조인트 그래프 - 산점도, 히스토그램\n",
    "sns.jointplot(x='weight', y='mpg', data=ndf)              # 회귀선 없음\n",
    "sns.jointplot(x='weight', y='mpg', kind='reg', data=ndf)  # 회귀선 표시\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn pariplot으로 두 변수 간의 모든 경우의 수 그리기\n",
    "sns.pairplot(ndf)  \n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Step 4: 데이터셋 구분 - 훈련용(train data)/ 검증용(test data)\n",
    "'''\n",
    "\n",
    "# 속성(변수) 선택\n",
    "X=ndf[['weight']]  #독립 변수 X\n",
    "y=ndf['mpg']       #종속 변수 Y\n",
    "\n",
    "# train data 와 test data로 구분(7:3 비율)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,               #독립 변수 \n",
    "                                                    y,               #종속 변수\n",
    "                                                    test_size=0.3,   #검증 30%\n",
    "                                                    random_state=10) #랜덤 추출 값 \n",
    "\n",
    "print('train data 개수: ', len(X_train))\n",
    "print('test data 개수: ', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Step 5: 단순회귀분석 모형 - sklearn 사용\n",
    "'''\n",
    "\n",
    "# sklearn 라이브러리에서 선형회귀분석 모듈 가져오기\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 단순회귀분석 모형 객체 생성\n",
    "lr = LinearRegression()   \n",
    "\n",
    "# train data를 가지고 모형 학습\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# 학습을 마친 모형에 test data를 적용하여 결정계수(R-제곱) 계산\n",
    "r_square = lr.score(X_test, y_test)\n",
    "print(r_square)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결정계수는 추정한 선형 모형이 주어진 자료에 적합한 정도를 재는 척도 임\n",
    "### 결정계수의 값은 0에서 1사이에 있으며, 종속변인과 독립변인 사이에 상관관계가 높을수록 1에 가까워짐 \n",
    "### 결정계수가 0에 가까운 값을 가지는 회귀모형은 유용성이 낮은 반면, 결정계수의 값이 클수록 회귀모형의 유용성이 높다고 판단함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀식의 기울기\n",
    "print('기울기 a: ', lr.coef_)\n",
    "print('\\n')\n",
    "\n",
    "# 회귀식의 y절편\n",
    "print('y절편 b', lr.intercept_)\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모형에 전체 X 데이터를 입력하여 예측한 값 y_hat을 실제 값 y와 비교 \n",
    "y_hat = lr.predict(X)\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax1 = sns.kdeplot(y, label=\"y\")\n",
    "ax2 = sns.kdeplot(y_hat, label=\"y_hat\", ax=ax1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다항회귀분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 예제 7-2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "'''\n",
    "[Step 1 ~ 4] 데이터 준비 \n",
    "'''\n",
    "# CSV 파일을 데이터프레임으로 변환\n",
    "df = pd.read_csv('./data/auto-mpg.csv', header=None)\n",
    "\n",
    "# 열 이름 지정\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight',\n",
    "              'acceleration','model year','origin','name'] \n",
    "\n",
    "# horsepower 열의 자료형 변경 (문자열 ->숫자)\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)      # '?'을 np.nan으로 변경\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True)   # 누락데이터 행을 삭제\n",
    "df['horsepower'] = df['horsepower'].astype('float')      # 문자열을 실수형으로 변환\n",
    "\n",
    "# 분석에 활용할 열(속성)을 선택 (연비, 실린더, 출력, 중량)\n",
    "ndf = df[['mpg', 'cylinders', 'horsepower', 'weight']]\n",
    "\n",
    "# ndf 데이터를 train data 와 test data로 구분(7:3 비율)\n",
    "X=ndf[['weight']]  #독립 변수 X\n",
    "y=ndf['mpg']     #종속 변수 Y\n",
    "\n",
    "# train data 와 test data로 구분(7:3 비율)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10) \n",
    "\n",
    "print('훈련 데이터: ', X_train.shape)\n",
    "print('검증 데이터: ', X_test.shape)   \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Step 5: 비선형회귀분석 모형 - sklearn 사용\n",
    "'''\n",
    "\n",
    "# sklearn 라이브러리에서 필요한 모듈 가져오기 \n",
    "from sklearn.linear_model import LinearRegression      #선형회귀분석\n",
    "from sklearn.preprocessing import PolynomialFeatures   #다항식 변환\n",
    "\n",
    "# 다항식 변환 \n",
    "poly = PolynomialFeatures(degree=2)               #2차항 적용\n",
    "X_train_poly=poly.fit_transform(X_train)     #X_train 데이터를 2차항으로 변형\n",
    "\n",
    "print('원 데이터: ', X_train.shape)\n",
    "print('2차항 변환 데이터: ', X_train_poly.shape)  \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data를 가지고 모형 학습\n",
    "pr = LinearRegression()   \n",
    "pr.fit(X_train_poly, y_train)\n",
    "\n",
    "# 학습을 마친 모형에 test data를 적용하여 결정계수(R-제곱) 계산\n",
    "X_test_poly = poly.fit_transform(X_test)       #X_test 데이터를 2차항으로 변형\n",
    "r_square = pr.score(X_test_poly,y_test)\n",
    "print(r_square)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data의 산점도와 test data로 예측한 회귀선을 그래프로 출력 \n",
    "y_hat_test = pr.predict(X_test_poly)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(X_train, y_train, 'o', label='Train Data')  # 데이터 분포\n",
    "ax.plot(X_test, y_hat_test, 'r+', label='Predicted Value') # 모형이 학습한 회귀선\n",
    "ax.legend(loc='best')\n",
    "plt.xlabel('weight')\n",
    "plt.ylabel('mpg')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모형에 전체 X 데이터를 입력하여 예측한 값 y_hat을 실제 값 y와 비교 \n",
    "X_ploy = poly.fit_transform(X)\n",
    "y_hat = pr.predict(X_ploy)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax1 = sns.kdeplot(y, label=\"y\")\n",
    "ax2 = sns.kdeplot(y_hat, label=\"y_hat\", ax=ax1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다중회귀분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 기본 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "'''\n",
    "[Step 1 ~ 3] 데이터 준비 \n",
    "'''\n",
    "# CSV 파일을 데이터프레임으로 변환\n",
    "df = pd.read_csv('./data/auto-mpg.csv', header=None)\n",
    "\n",
    "# 열 이름 지정\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight',\n",
    "              'acceleration','model year','origin','name'] \n",
    "\n",
    "# horsepower 열의 자료형 변경 (문자열 ->숫자)\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)      # '?'을 np.nan으로 변경\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True)   # 누락데이터 행을 삭제\n",
    "df['horsepower'] = df['horsepower'].astype('float')      # 문자열을 실수형으로 변환\n",
    "\n",
    "# 분석에 활용할 열(속성)을 선택 (연비, 실린더, 출력, 중량)\n",
    "ndf = df[['mpg', 'cylinders', 'horsepower', 'weight']]\n",
    "\n",
    "\n",
    "'''\n",
    "Step 4: 데이터셋 구분 - 훈련용(train data)/ 검증용(test data)\n",
    "'''\n",
    "\n",
    "# 속성(변수) 선택\n",
    "X=ndf[['cylinders', 'horsepower', 'weight']]  #독립 변수 X1, X2, X3\n",
    "y=ndf['mpg']     #종속 변수 Y\n",
    "\n",
    "# train data 와 test data로 구분(7:3 비율)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10) \n",
    "\n",
    "print('훈련 데이터: ', X_train.shape)\n",
    "print('검증 데이터: ', X_test.shape)   \n",
    "print('\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Step 5: 다중회귀분석 모형 - sklearn 사용\n",
    "'''\n",
    "\n",
    "# sklearn 라이브러리에서 선형회귀분석 모듈 가져오기\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 단순회귀분석 모형 객체 생성\n",
    "lr = LinearRegression()   \n",
    "\n",
    "# train data를 가지고 모형 학습\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# 학습을 마친 모형에 test data를 적용하여 결정계수(R-제곱) 계산\n",
    "r_square = lr.score(X_test, y_test)\n",
    "print(r_square)\n",
    "print('\\n')\n",
    "\n",
    "# 회귀식의 기울기\n",
    "print('X 변수의 계수 a: ', lr.coef_)\n",
    "print('\\n')\n",
    "\n",
    "# 회귀식의 y절편\n",
    "print('상수항 b', lr.intercept_)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data의 산점도와 test data로 예측한 회귀선을 그래프로 출력 \n",
    "y_hat = lr.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax1 = sns.kdeplot(y_test, label=\"y_test\")\n",
    "ax2 = sns.kdeplot(y_hat, label=\"y_hat\", ax=ax1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN - K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 기본 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "'''\n",
    "[Step 1] 데이터 준비 - Seaborn에서 제공하는 titanic 데이터셋 가져오기\n",
    "'''\n",
    "\n",
    "# load_dataset 함수를 사용하여 데이터프레임으로 변환\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# 데이터 살펴보기\n",
    "print(df.head())   \n",
    "print('\\n')\n",
    "\n",
    "#  IPython 디스플레이 설정 - 출력할 열의 개수 한도 늘리기\n",
    "pd.set_option('display.max_columns', 15)\n",
    "print(df.head())   \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Step 2] 데이터 탐색\n",
    "'''\n",
    "\n",
    "# 데이터 자료형 확인\n",
    "print(df.info())  \n",
    "print('\\n')\n",
    "\n",
    "# NaN값이 많은 deck 열을 삭제, embarked와 내용이 겹치는 embark_town 열을 삭제\n",
    "rdf = df.drop(['deck', 'embark_town'], axis=1)  \n",
    "print(rdf.columns.values)\n",
    "print('\\n')\n",
    "\n",
    "# age 열에 나이 데이터가 없는 모든 행을 삭제 - age 열(891개 중 177개의 NaN 값)\n",
    "rdf = rdf.dropna(subset=['age'], how='any', axis=0)  \n",
    "print(len(rdf))\n",
    "print('\\n')\n",
    "\n",
    "# embarked 열의 NaN값을 승선도시 중에서 가장 많이 출현한 값으로 치환하기\n",
    "most_freq = rdf['embarked'].value_counts(dropna=True).idxmax()   \n",
    "print(most_freq)\n",
    "print('\\n')\n",
    "\n",
    "print(rdf.describe(include='all'))\n",
    "print('\\n')\n",
    "\n",
    "rdf['embarked'].fillna(most_freq, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Step 3] 분석에 사용할 속성을 선택\n",
    "'''\n",
    "\n",
    "# 분석에 활용할 열(속성)을 선택 \n",
    "ndf = rdf[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'embarked']]\n",
    "print(ndf.head())   \n",
    "print('\\n')\n",
    "\n",
    "# 원핫인코딩 - 범주형 데이터를 모형이 인식할 수 있도록 숫자형으로 변환\n",
    "onehot_sex = pd.get_dummies(ndf['sex'])\n",
    "ndf = pd.concat([ndf, onehot_sex], axis=1)\n",
    "\n",
    "onehot_embarked = pd.get_dummies(ndf['embarked'], prefix='town')\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis=1)\n",
    "\n",
    "ndf.drop(['sex', 'embarked'], axis=1, inplace=True)\n",
    "print(ndf.head())   \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Step 4] 데이터셋 구분 - 훈련용(train data)/ 검증용(test data)\n",
    "'''\n",
    "\n",
    "# 속성(변수) 선택\n",
    "X=ndf[['pclass', 'age', 'sibsp', 'parch', 'female', 'male', \n",
    "       'town_C', 'town_Q', 'town_S']]  #독립 변수 X\n",
    "y=ndf['survived']                      #종속 변수 Y\n",
    "\n",
    "# 설명 변수 데이터를 정규화(normalization)\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "# train data 와 test data로 구분(7:3 비율)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10) \n",
    "\n",
    "print('train data 개수: ', X_train.shape)\n",
    "print('test data 개수: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Step 5] KNN 분류 모형 - sklearn 사용\n",
    "'''\n",
    "\n",
    "# sklearn 라이브러리에서 KNN 분류 모형 가져오기\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 모형 객체 생성 (k=5로 설정)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# train data를 가지고 모형 학습\n",
    "knn.fit(X_train, y_train)   \n",
    "\n",
    "# test data를 가지고 y_hat을 예측 (분류) \n",
    "y_hat = knn.predict(X_test)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])\n",
    "\n",
    "# 모형 성능 평가 - Confusion Matrix 계산\n",
    "from sklearn import metrics \n",
    "knn_matrix = metrics.confusion_matrix(y_test, y_hat)  \n",
    "print(knn_matrix)\n",
    "\n",
    "# 모형 성능 평가 - 평가지표 계산\n",
    "knn_report = metrics.classification_report(y_test, y_hat)            \n",
    "print(knn_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 기본 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "'''\n",
    "[Step 1] 데이터 준비/ 기본 설정\n",
    "'''\n",
    "\n",
    "# load_dataset 함수를 사용하여 데이터프레임으로 변환\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "#  IPython 디스플레이 설정 - 출력할 열의 개수 한도 늘리기\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "\n",
    "'''\n",
    "[Step 2] 데이터 탐색/ 전처리\n",
    "'''\n",
    "\n",
    "# NaN값이 많은 deck 열을 삭제, embarked와 내용이 겹치는 embark_town 열을 삭제\n",
    "rdf = df.drop(['deck', 'embark_town'], axis=1)  \n",
    "\n",
    "# age 열에 나이 데이터가 없는 모든 행을 삭제 - age 열(891개 중 177개의 NaN 값)\n",
    "rdf = rdf.dropna(subset=['age'], how='any', axis=0)  \n",
    "\n",
    "# embarked 열의 NaN값을 승선도시 중에서 가장 많이 출현한 값으로 치환하기\n",
    "most_freq = rdf['embarked'].value_counts(dropna=True).idxmax()   \n",
    "rdf['embarked'].fillna(most_freq, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Step 3] 분석에 사용할 속성을 선택\n",
    "'''\n",
    "\n",
    "# 분석에 활용할 열(속성)을 선택 \n",
    "ndf = rdf[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'embarked']]\n",
    "\n",
    "# 원핫인코딩 - 범주형 데이터를 모형이 인식할 수 있도록 숫자형으로 변환\n",
    "onehot_sex = pd.get_dummies(ndf['sex'])\n",
    "ndf = pd.concat([ndf, onehot_sex], axis=1)\n",
    "\n",
    "onehot_embarked = pd.get_dummies(ndf['embarked'], prefix='town')\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis=1)\n",
    "\n",
    "ndf.drop(['sex', 'embarked'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Step 4] 데이터셋 구분 - 훈련용(train data)/ 검증용(test data)\n",
    "'''\n",
    "\n",
    "# 속성(변수) 선택\n",
    "X=ndf[['pclass', 'age', 'sibsp', 'parch', 'female', 'male', \n",
    "       'town_C', 'town_Q', 'town_S']]  #독립 변수 X\n",
    "y=ndf['survived']                      #종속 변수 Y\n",
    "\n",
    "# 설명 변수 데이터를 정규화(normalization)\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "# train data 와 test data로 구분(7:3 비율)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10) \n",
    "\n",
    "print('train data 개수: ', X_train.shape)\n",
    "print('test data 개수: ', X_test.shape)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Step 5] SVM 분류 모형 - sklearn 사용\n",
    "'''\n",
    "\n",
    "# sklearn 라이브러리에서 SVM 분류 모형 가져오기\n",
    "from sklearn import svm\n",
    "\n",
    "# 모형 객체 생성 (kernel='rbf' 적용)\n",
    "svm_model = svm.SVC(kernel='rbf')\n",
    "\n",
    "# train data를 가지고 모형 학습\n",
    "svm_model.fit(X_train, y_train)   \n",
    "\n",
    "# test data를 가지고 y_hat을 예측 (분류) \n",
    "y_hat = svm_model.predict(X_test)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모형 성능 평가 - Confusion Matrix 계산\n",
    "from sklearn import metrics \n",
    "svm_matrix = metrics.confusion_matrix(y_test, y_hat)  \n",
    "print(svm_matrix)\n",
    "print('\\n')\n",
    "\n",
    "# 모형 성능 평가 - 평가지표 계산\n",
    "svm_report = metrics.classification_report(y_test, y_hat)            \n",
    "print(svm_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 기본 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "[Step 1] 데이터 준비/ 기본 설정\n",
    "'''\n",
    "\n",
    "# Breast Cancer 데이터셋 가져오기 (출처: UCI ML Repository)\n",
    "uci_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/\\\n",
    "breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "df = pd.read_csv(uci_path, header=None)\n",
    "\n",
    "# 열 이름 지정\n",
    "df.columns = ['id','clump','cell_size','cell_shape', 'adhesion','epithlial',\n",
    "              'bare_nuclei','chromatin','normal_nucleoli', 'mitoses', 'class'] \n",
    "\n",
    "#  IPython 디스플레이 설정 - 출력할 열의 개수 한도 늘리기\n",
    "pd.set_option('display.max_columns', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Step 2] 데이터 탐색\n",
    "'''\n",
    "\n",
    "# 데이터 살펴보기\n",
    "print(df.head())   \n",
    "print('\\n')\n",
    "\n",
    "# 데이터 자료형 확인\n",
    "print(df.info())  \n",
    "print('\\n')\n",
    "\n",
    "# 데이터 통계 요약정보 확인\n",
    "print(df.describe())\n",
    "print('\\n')\n",
    "\n",
    "# bare_nuclei 열의 자료형 변경 (문자열 ->숫자)\n",
    "print(df['bare_nuclei'].unique())                         # bare_nuclei 열의 고유값 확인\n",
    "print('\\n')\n",
    "\n",
    "df['bare_nuclei'].replace('?', np.nan, inplace=True)      # '?'을 np.nan으로 변경\n",
    "df.dropna(subset=['bare_nuclei'], axis=0, inplace=True)   # 누락데이터 행을 삭제\n",
    "df['bare_nuclei'] = df['bare_nuclei'].astype('int')       # 문자열을 정수형으로 변환\n",
    "\n",
    "print(df.describe())                                      # 데이터 통계 요약정보 확인\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Step 3] 데이터셋 구분 - 훈련용(train data)/ 검증용(test data)\n",
    "'''\n",
    "\n",
    "# 속성(변수) 선택\n",
    "X=df[['clump','cell_size','cell_shape', 'adhesion','epithlial',\n",
    "      'bare_nuclei','chromatin','normal_nucleoli', 'mitoses']]  #설명 변수 X\n",
    "y=df['class']                                                   #예측 변수 Y\n",
    "\n",
    "# 설명 변수 데이터를 정규화\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "# train data 와 test data로 구분(7:3 비율)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10) \n",
    "\n",
    "print('train data 개수: ', X_train.shape)\n",
    "print('test data 개수: ', X_test.shape)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Step 4] Decision Tree 분류 모형 - sklearn 사용\n",
    "'''\n",
    "\n",
    "# sklearn 라이브러리에서 Decision Tree 분류 모형 가져오기\n",
    "from sklearn import tree\n",
    "\n",
    "# 모형 객체 생성 (criterion='entropy' 적용)\n",
    "tree_model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=5)\n",
    "\n",
    "# train data를 가지고 모형 학습\n",
    "tree_model.fit(X_train, y_train)   \n",
    "\n",
    "# test data를 가지고 y_hat을 예측 (분류) \n",
    "y_hat = tree_model.predict(X_test)      # 2: benign(양성), 4: malignant(악성)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모형 성능 평가 - Confusion Matrix 계산\n",
    "from sklearn import metrics \n",
    "tree_matrix = metrics.confusion_matrix(y_test, y_hat)  \n",
    "print(tree_matrix)\n",
    "print('\\n')\n",
    "\n",
    "# 모형 성능 평가 - 평가지표 계산\n",
    "tree_report = metrics.classification_report(y_test, y_hat)            \n",
    "print(tree_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 기본 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "'''\n",
    "[Step 1] 데이터 준비\n",
    "'''\n",
    "\n",
    "# Wholesale customers 데이터셋 가져오기 (출처: UCI ML Repository)\n",
    "uci_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/\\\n",
    "00292/Wholesale%20customers%20data.csv'\n",
    "df = pd.read_csv(uci_path, header=0)\n",
    "\n",
    "\n",
    "'''\n",
    "[Step 2] 데이터 탐색\n",
    "'''\n",
    "\n",
    "# 데이터 살펴보기\n",
    "print(df.head())   \n",
    "print('\\n')\n",
    "\n",
    "# 데이터 자료형 확인\n",
    "print(df.info())  \n",
    "print('\\n')\n",
    "\n",
    "# 데이터 통계 요약정보 확인\n",
    "print(df.describe())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Step 3] 데이터 전처리\n",
    "'''\n",
    "\n",
    "# 분석에 사용할 속성을 선택\n",
    "X = df.iloc[:, :]\n",
    "print(X[:5])\n",
    "print('\\n')\n",
    "\n",
    "# 설명 변수 데이터를 정규화\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "print(X[:5])\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Step 4] k-means 군집 모형 - sklearn 사용\n",
    "'''\n",
    "\n",
    "# sklearn 라이브러리에서 cluster 군집 모형 가져오기\n",
    "from sklearn import cluster\n",
    "\n",
    "# 모형 객체 생성 \n",
    "kmeans = cluster.KMeans(init='k-means++', n_clusters=5, n_init=10)\n",
    "\n",
    "# 모형 학습\n",
    "kmeans.fit(X)   \n",
    "\n",
    "# 예측 (군집) \n",
    "cluster_label = kmeans.labels_   \n",
    "print(cluster_label)\n",
    "print('\\n')\n",
    "\n",
    "# 예측 결과를 데이터프레임에 추가\n",
    "df['Cluster'] = cluster_label\n",
    "print(df.head())   \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프로 표현 - 시각화\n",
    "df.plot(kind='scatter', x='Grocery', y='Frozen', c='Cluster', cmap='Set1', \n",
    "        colorbar=False, figsize=(10, 10))\n",
    "df.plot(kind='scatter', x='Milk', y='Delicassen', c='Cluster', cmap='Set1', \n",
    "        colorbar=True, figsize=(10, 10))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 큰 값으로 구성된 클러스터(0, 4)를 제외 - 값이 몰려 있는 구간을 자세하게 분석\n",
    "mask = (df['Cluster'] == 0) | (df['Cluster'] == 4)\n",
    "ndf = df[~mask]\n",
    "\n",
    "ndf.plot(kind='scatter', x='Grocery', y='Frozen', c='Cluster', cmap='Set1', \n",
    "        colorbar=False, figsize=(10, 10))\n",
    "ndf.plot(kind='scatter', x='Milk', y='Delicassen', c='Cluster', cmap='Set1', \n",
    "        colorbar=True, figsize=(10, 10))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN - Density-Based Spatial Clustering of Applications with Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 기본 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import folium\n",
    "\n",
    "\n",
    "'''\n",
    "[Step 1] 데이터 준비/ 기본 설정\n",
    "'''\n",
    "\n",
    "# 서울시내 중학교 진학률 데이터셋 (출처: 교육???)\n",
    "file_path = './data/2016_middle_shcool_graduates_report.xlsx'\n",
    "df = pd.read_excel(file_path, header=0)\n",
    "\n",
    "# IPython Console 디스플레이 옵션 설정하기\n",
    "pd.set_option('display.width', None)        # 출력화면의 너비\n",
    "pd.set_option('display.max_rows', 100)      # 출력할 행의 개수 한도\n",
    "pd.set_option('display.max_columns', 10)    # 출력할 열의 개수 한도\n",
    "pd.set_option('display.max_colwidth', 20)   # 출력할 열의 너비\n",
    "pd.set_option('display.unicode.east_asian_width', True)   # 유니코드 사용 너비 조정\n",
    "\n",
    "# 열 이름 배열을 출력\n",
    "print(df.columns.values)   \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Step 2] 데이터 탐색\n",
    "'''\n",
    "\n",
    "# 데이터 살펴보기\n",
    "print(df.head())   \n",
    "print('\\n')\n",
    "\n",
    "# 데이터 자료형 확인\n",
    "print(df.info())  \n",
    "print('\\n')\n",
    "\n",
    "# 데이터 통계 요약정보 확인\n",
    "print(df.describe())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지도에 위치 표시\n",
    "mschool_map = folium.Map(location=[37.55,126.98], tiles='Stamen Terrain', \n",
    "                        zoom_start=12)\n",
    "\n",
    "# 중학교 위치정보를 CircleMarker로 표시\n",
    "for name, lat, lng in zip(df.학교명, df.위도, df.경도):\n",
    "    folium.CircleMarker([lat, lng],\n",
    "                        radius=5,              # 원의 반지름\n",
    "                        color='brown',         # 원의 둘레 색상\n",
    "                        fill=True,\n",
    "                        fill_color='coral',    # 원을 채우는 색\n",
    "                        fill_opacity=0.7,      # 투명도    \n",
    "                        popup=name\n",
    "    ).add_to(mschool_map)\n",
    "\n",
    "# 지도를 html 파일로 저장하기\n",
    "mschool_map.save('output/seoul_mschool_location.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Step 3] 데이터 전처리\n",
    "'''\n",
    "\n",
    "# 원핫인코딩(더미 변수)\n",
    "from sklearn import preprocessing    \n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()     # label encoder 생성\n",
    "onehot_encoder = preprocessing.OneHotEncoder()   # one hot encoder 생성\n",
    "\n",
    "onehot_location = label_encoder.fit_transform(df['지역'])\n",
    "onehot_code = label_encoder.fit_transform(df['코드'])\n",
    "onehot_type = label_encoder.fit_transform(df['유형'])\n",
    "onehot_day = label_encoder.fit_transform(df['주야'])\n",
    "\n",
    "df['location'] = onehot_location\n",
    "df['code'] = onehot_code\n",
    "df['type'] = onehot_type\n",
    "df['day'] = onehot_day\n",
    "\n",
    "print(df.head())   \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Step 4] DBSCAN 군집 모형 - sklearn 사용\n",
    "'''\n",
    "\n",
    "# sklearn 라이브러리에서 cluster 군집 모형 가져오기 \n",
    "from sklearn import cluster\n",
    "\n",
    "# 분석에 사용할 속성을 선택 (과학고, 외고국제고, 자사고 진학률)\n",
    "columns_list = [9, 10, 13]\n",
    "X = df.iloc[:, columns_list]\n",
    "print(X[:5])\n",
    "print('\\n')\n",
    "\n",
    "# 설명 변수 데이터를 정규화\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "# DBSCAN 모형 객체 생성\n",
    "dbm = cluster.DBSCAN(eps=0.2, min_samples=5)\n",
    "\n",
    "# 모형 학습\n",
    "dbm.fit(X)   \n",
    " \n",
    "# 예측 (군집) \n",
    "cluster_label = dbm.labels_   \n",
    "print(cluster_label)\n",
    "print('\\n')\n",
    "\n",
    "# 예측 결과를 데이터프레임에 추가\n",
    "df['Cluster'] = cluster_label\n",
    "print(df.head())   \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클러스터 값으로 그룹화하고, 그룹별로 내용 출력 (첫 5행만 출력)\n",
    "grouped_cols = [0, 1, 3] + columns_list\n",
    "grouped = df.groupby('Cluster')\n",
    "for key, group in grouped:\n",
    "    print('* key :', key)\n",
    "    print('* number :', len(group))    \n",
    "    print(group.iloc[:, grouped_cols].head())\n",
    "    print('\\n')\n",
    "\n",
    "# 그래프로 표현 - 시각화\n",
    "colors = {-1:'gray', 0:'coral', 1:'blue', 2:'green', 3:'red', 4:'purple', \n",
    "          5:'orange', 6:'brown', 7:'brick', 8:'yellow', 9:'magenta', 10:'cyan', 11:'pink'}\n",
    "\n",
    "cluster_map = folium.Map(location=[37.55,126.98], tiles='Stamen Terrain', \n",
    "                        zoom_start=12)\n",
    "\n",
    "for name, lat, lng, clus in zip(df.학교명, df.위도, df.경도, df.Cluster):  \n",
    "    folium.CircleMarker([lat, lng],\n",
    "                        radius=5,                   # 원의 반지름\n",
    "                        color=colors[clus],         # 원의 둘레 색상\n",
    "                        fill=True,\n",
    "                        fill_color=colors[clus],    # 원을 채우는 색\n",
    "                        fill_opacity=0.7,           # 투명도    \n",
    "                        popup=name\n",
    "    ).add_to(cluster_map)\n",
    "\n",
    "# 지도를 html 파일로 저장하기\n",
    "cluster_map.save('output/seoul_mschool_cluster.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X2 데이터셋에 대하여 위의 과정을 반복(과학고, 외고국제고, 자사고 진학률 + 유형)\n",
    "columns_list2 = [9, 10, 13, 22]\n",
    "X2 = df.iloc[:, columns_list2]\n",
    "print(X2[:5])\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "X2 = preprocessing.StandardScaler().fit(X2).transform(X2)\n",
    "dbm2 = cluster.DBSCAN(eps=0.2, min_samples=5)\n",
    "dbm2.fit(X2)  \n",
    "df['Cluster2'] = dbm2.labels_   \n",
    "\n",
    "grouped2_cols = [0, 1, 3] + columns_list2\n",
    "grouped2 = df.groupby('Cluster2')\n",
    "for key, group in grouped2:\n",
    "    print('* key :', key)\n",
    "    print('* number :', len(group))    \n",
    "    print(group.iloc[:, grouped2_cols].head())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster2_map = folium.Map(location=[37.55,126.98], tiles='Stamen Terrain', \n",
    "                        zoom_start=12)\n",
    "\n",
    "for name, lat, lng, clus in zip(df.학교명, df.위도, df.경도, df.Cluster2):  \n",
    "    folium.CircleMarker([lat, lng],\n",
    "                        radius=5,                   # 원의 반지름\n",
    "                        color=colors[clus],         # 원의 둘레 색상\n",
    "                        fill=True,\n",
    "                        fill_color=colors[clus],    # 원을 채우는 색\n",
    "                        fill_opacity=0.7,           # 투명도    \n",
    "                        popup=name\n",
    "    ).add_to(cluster2_map)\n",
    "\n",
    "# 지도를 html 파일로 저장하기\n",
    "cluster2_map.save('./output/seoul_mschool_cluster2.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X3 데이터셋에 대하여 위의 과정을 반복(과학고, 외고_국제고)\n",
    "columns_list3 = [9, 10]\n",
    "X3 = df.iloc[:, columns_list3]\n",
    "print(X3[:5])\n",
    "print('\\n')\n",
    "\n",
    "X3 = preprocessing.StandardScaler().fit(X3).transform(X3)\n",
    "dbm3 = cluster.DBSCAN(eps=0.2, min_samples=5)\n",
    "dbm3.fit(X3)  \n",
    "df['Cluster3'] = dbm3.labels_   \n",
    "\n",
    "grouped3_cols = [0, 1, 3] + columns_list3\n",
    "grouped3 = df.groupby('Cluster3')\n",
    "for key, group in grouped3:\n",
    "    print('* key :', key)\n",
    "    print('* number :', len(group))    \n",
    "    print(group.iloc[:, grouped3_cols].head())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster3_map = folium.Map(location=[37.55,126.98], tiles='Stamen Terrain', \n",
    "                        zoom_start=12)\n",
    "\n",
    "for name, lat, lng, clus in zip(df.학교명, df.위도, df.경도, df.Cluster3):  \n",
    "    folium.CircleMarker([lat, lng],\n",
    "                        radius=5,                   # 원의 반지름\n",
    "                        color=colors[clus],         # 원의 둘레 색상\n",
    "                        fill=True,\n",
    "                        fill_color=colors[clus],    # 원을 채우는 색\n",
    "                        fill_opacity=0.7,           # 투명도    \n",
    "                        popup=name\n",
    "    ).add_to(cluster3_map)\n",
    "\n",
    "# 지도를 html 파일로 저장하기\n",
    "cluster3_map.save('output/seoul_mschool_cluster3.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydatavenv",
   "language": "python",
   "name": "pydatavenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
